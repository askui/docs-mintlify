---
title: "Agent Types"
description: "Understand AskUI's specialized agent types for different platforms"
---

Multi-platform automation presents unique challenges that have shaped AskUI's architectural approach. Rather than building a single, monolithic agent that attempts to handle all platforms, AskUI employs specialized agent types that understand the distinct characteristics and interaction patterns of different environments.

## The Multi-Platform Challenge

Traditional automation tools often struggle with platform diversity because they apply a one-size-fits-all approach. Desktop applications behave differently from mobile apps, which behave differently from web applications. Each platform has its own:

- **Interaction paradigms**: Desktop uses mouse and keyboard, mobile uses touch gestures, web applications combine both
- **UI element hierarchies**: Desktop controls follow OS conventions, mobile apps use platform-specific widgets, web pages use DOM structures
- **Performance characteristics**: Desktop apps run locally, mobile apps have resource constraints, web apps depend on network connectivity
- **Security models**: Each platform has different access controls and permissions
- **Platform-dependent functionality**: Android devices offer unique capabilities like unlock screen automation, WiFi enable/disable controls, and system-level settings access that don't exist on other platforms

AskUI's response to this complexity is architectural specialization rather than generalization.

## Agent Specialization Philosophy

AskUI's multi-platform support is built on the principle that **specialized agents enable superior developer experience through platform-native APIs**. This design philosophy manifests in several ways:

### VisionAgent: Desktop-Native Developer Experience

The VisionAgent provides a desktop-centric API that speaks the language of desktop interaction patterns. The IDE can intelligently suggest desktop-specific functions, making development intuitive for desktop automation scenarios.

```python
from askui import VisionAgent

with VisionAgent() as agent:
    # Seamlessly handles both desktop apps and web browsers
    agent.click("file menu")
    agent.type("username field", "john.doe")
    agent.mouse_move("submit button")
```

The VisionAgent's developer experience focuses on:
- **Desktop-familiar terminology**: Uses `click`, `mouse_move`, `drag_and_drop` - terms that match desktop interaction patterns
- **IDE autocomplete support**: The IDE can recommend desktop-specific functions based on context
- **Platform-appropriate abstractions**: Provides APIs that match how developers think about desktop automation

### AndroidVisionAgent: Mobile-Native Developer Experience

The AndroidVisionAgent provides a mobile-centric API that uses Android's native interaction vocabulary. The IDE can surface Android-specific functions and system capabilities, enabling developers to discover platform features naturally.

```python
from askui import AndroidVisionAgent

with AndroidVisionAgent() as agent:
    # Mobile-native interactions using Android terminology
    agent.tap("settings")
    agent.type("search field", "bluetooth")
    agent.act("Navigate to bluetooth settings")
```

The AndroidVisionAgent's developer experience emphasizes:
- **Mobile-familiar terminology**: Uses `tap`, `swipe`, `long_press` - terms that match mobile interaction patterns
- **Android system integration**: Provides `back_key()`, `home_key()`, `enable_wifi()` - Android-specific capabilities
- **IDE discoverability**: The IDE can recommend Android-specific functions and system features as developers type

## Design Trade-offs and Architectural Decisions

The decision to create specialized agents rather than a unified interface represents a fundamental trade-off in automation architecture. This choice has several implications:

### Developer Experience vs. Universal APIs

**Why platform-native APIs enhance DevEx**: Early automation tools attempted to create universal interfaces that could handle any platform. This approach consistently failed from a developer experience perspective because:
- Developers had to learn generic abstractions that didn't match their mental models
- IDE tooling couldn't provide meaningful autocomplete suggestions for platform-specific features
- The lowest common denominator approach hid platform capabilities behind generic interfaces
- Developers ended up writing platform-specific workarounds anyway

**The benefit of specialization**: AskUI's approach allows developers to work with familiar platform terminology while enabling IDEs to provide intelligent, context-aware suggestions for platform-specific capabilities.

### Consistency vs. Platform Idioms

AskUI balances consistency with platform idioms by maintaining **conceptual consistency** while allowing **terminology divergence**. Both agents share core concepts like [`locate()`](/04-reference/01-agent-frameworks/02-python/02-vision-agent-api/agent#locate), [`get()`](/04-reference/01-agent-frameworks/02-python/02-vision-agent-api/agent#get), and [`act()`](/04-reference/01-agent-frameworks/02-python/02-vision-agent-api/agent#act), but their interaction methods use platform-native terminology.

This approach recognizes that while developers want consistent mental models, they also want to work with familiar platform terminology. IDEs can leverage this specialization to provide better developer tooling and discoverability.

### Platform Evolution and Future-Proofing

The specialized agent architecture also considers how platforms evolve differently:

- **Desktop platforms** are becoming more web-centric, with applications increasingly built on web technologies
- **Mobile platforms** are moving toward more contextual, AI-driven interfaces
- **Emerging platforms** like VR/AR, IoT devices, and voice interfaces have fundamentally different interaction paradigms

By separating platform concerns into specialized agents, AskUI can evolve each agent independently as platforms change, without forcing artificial compatibility constraints.

## Next Steps

- Learn about [Automation Paradigms](/03-explanation/01-foundations/automation-paradigms) to understand how these agents operate
- Explore platform-specific [Best Practices](/03-explanation/02-best-practices/01-element-selection/01-element-selection) for effective automation
- Read about [AI Models](/03-explanation/03-ai-models/01-grounding-models) to understand the intelligence behind agent types
