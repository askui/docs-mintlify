---
title: Frequently Asked Questions (FAQ)
description: 'Welcome to the AskUI FAQ! Below you'll find answers to common questions and helpful troubleshooting tips. For more, check out our documentation.'
---



## ‚ùì What is AskUI?

AskUI is an AI-powered UI automation tool that interacts with applications visually - like a human would. It enables automation across any platform, UI, or application without relying on code-level selectors or APIs.

---

## üöÄ What can I automate with AskUI?

You can automate:

- Web, desktop, and hybrid applications
- UI testing and QA workflows
- Test native apps with hardware integration
- Document-based processes
- Repetitive operational tasks

---

## üõ†Ô∏è Do I need to write code?

AskUI provides a developer-friendly [TypeScript SDK](https://github.com/askui/askui) and a [Python Vision Agent](https://github.com/askui/vision-agent), and we're working on more intuitive, low-code/no-code options for non-dev users.

---

## üñºÔ∏è How does AskUI detect UI elements?

AskUI uses computer vision and OCR to recognize elements visually based on:

- Text labels
- Icons or logos
- Relative layout
- Element shapes and positions

This makes it highly flexible - even across dynamic or custom UIs. See more in the core concept.

---

## üß™ Can I use AskUI for automated testing?

Yes! AskUI is great for:

- UI regression testing
- End-to-end test cases
- Visual verification
- Cross-platform QA (including Android)

---

## ‚öôÔ∏è What platforms are supported?

- OS: Windows, macOS, Linux, Android, iOS (cominig soon)
- Apps: Any web or desktop app
- Mobile: Android (via emulator/screen mirroring)
- It¬¥s framework independent: You can use Electron, JavaFX, Java Swing, .NET apps, and more

## üß† What models is AskUI using?

AskUI uses a **layered system of AI models,** each with a distinct role in understanding, executing, and interacting with user interfaces. Here's how we classify and use them:

1. Grouding Models (Locators)
    1. Grounding models identify and interact with UI elements on the screen.
        1. Draw an image where a Grounding Model has
            1. The input is an UI Image and an Instruction e.g. click on logi button
            2. THe output is an list of bounding boxes 
2. Query Models (Asks)
    - Responsible for answering user queries or generating intelligent responses.
3. Large Action Models (act) (Multi Step)
    - Responsibilites
        - Goal to ‚Üí Planning
        - Delegate Grounding Models
        - Delegate Query Models
        - Reflection of Errors
    - UI-Tars
    - Computer-Use
    
    ### Which models do we have?
    
    | **Model Type** | **Model Name** | **Purpose** | **Teachable** | Online Trainable |
    | --- | --- | --- | --- | --- |
    | Grounding | UIDT-1 | Locate elements & understand screen | No | Partial |
    | Grounding | PTA-1 | Convert prompts into one-click actions | No | Yes |
    | Query | GPT-4 | Understand & respond to user queries | Yes | No |
    | Query | Computer Use | Understand & respond to user queries | Yes | No |
    | Large Action (act) | Computer Use | Plan and execute full workflows | Yes | No |
    | Large Action (act) | UI-Tars | Plan and execute full workflows | Yes | No |

[https://docs.askui.com/introduction/04-ai-models/01-grounding-models](https://docs.askui.com/introduction/04-ai-models/01-grounding-models)

### üß† What exactly is the **AskUI UIDT-1 Model?**

A powerful model composed of multiple specialized sub-models:

- **Element Detector**
    
    Trained to detect 9 key UI element types (like buttons, text fields, checkboxes, etc.).
    
- **End-to-End OCR (Optical Character Recognition)**
    
    Used to read and understand text in the UI:
    
    - **Text Recognition**: A *teachable model* that learns from user corrections.
    - **Text Detection**: Locates where text appears on the screen.
- **DSL (Domain-Specific Language)**
    
    Allows precise descriptions of UI actions.
    

### ‚ö° How does the **Prompt-to-Action (PTA-1)**  work? ‚Äì *Single-Step Execution*

- Converts natural language prompts into direct UI actions.
- Built as a *teachable model* to continuously improve from user feedback.

### üß† What is a **Large Action Models (LAM)** ‚Äì *Multi-Step Execution*

These are higher-level models responsible for planning and executing more complex workflows.

### Responsibilities:

- **Planning**: Understand a user goal and break it into steps.
- **Delegation**: Assign tasks to Grounding or Query models.
- **Reflection**: Analyze and correct errors during execution.

### Includes:

- **UI-Tars**: Task agents specialized in certain UI flows.
- **Computer-Use**: Models that simulate a real user interacting with a full application or system.

---

# üßë‚Äçüè´ What is the difference between Teaching vs. Training?

**Teaching** is about helping the model improve or adapt **without changing its underlying neural network weights.** 

Instead, you guide it using **examples, rules, or context.** It‚Äôs often about using **prompts, memory, or interaction history** to adjust model behavior in a targeted and efficient way.

### üß∞ Teaching in AskUI includes:

- **Prompt Engineering:** Giving clear, contextual instructions like *‚ÄúClick on the login button‚Äù* helps models interpret intent more accurately.
- **LLMs and LAMs are teacheable models, like GPT4, Anthropic Claude etc**

---

### üèãÔ∏è Training: Deep Learning, Long-Term Learning

**Training** involves changing the internal parameters of a model - its **weights -** through exposure to **large datasets** and feedback signals. This is computationally expensive and typically happens during development, online training or in batch processes. OCR re-teaching is on example of training and AskUI supports online training.

### üß∞ Online-Training in AskUI includes:

- [**OCR Re-Training (UIDT-1)](https://www.askui.com/blog-posts/how-to-retrain-your-text-elements-with-askui-ocr-teaching-app):**
    
    Our OCR engine is a composite of teachable and trainable models. While you can ‚Äúteach‚Äù it by correcting recognized text, deeper improvements (like recognizing new font types or edge cases) require training on more labeled images.
    
- [**Prompt-to-Action (e.g., PTA-1):**](https://docs.askui.com/02-api-reference/02-askui-suite/02-askui-suite/AskUIRemoteDeviceSnippingTool/Experimental/AskUI-NewAnnotationsForTraining)
    
    These models incorporate feedback from user corrections. For example, if a button click fails, and the user clarifies the intended target, the model updates its interpretation next time.
    

---

### üß† Why Use Both?

AskUI combines **training and teaching** because:

- **Teaching is agile**: It empowers users to refine behavior instantly.
- **Training is foundational**: It builds the core capabilities of the model.

| Aspect | Teaching | Training |
| --- | --- | --- |
| Speed | Immediate or near real-time | Takes time (minutes to hours) |
| Who does it? | Users or **automation** | Developers/Engineers |
| Affects Model Weights | ‚ùå No | ‚úÖ Yes |
| Flexibility | High - works with new scenarios | Medium - needs structured data |
| Example in AskUI | PTA-1 prompt learning, OCR tweaks | UIDT-1 model expansion |

---

## üîê Is AskUI secure?

Yes. AskUI runs automation on your infrastructure. Screenshots and input data are handled locally unless explicitly shared through cloud functions.

---

## üì¶ How do I install AskUI?

Typescript: Install the CLI with:

```bash
npm install -g @askui/cli

```

Python: Install with:

```bash
pip install askui

```

Then follow our [Getting Started Guide](https://docs.askui.com/introduction/01-introduction/02-quickstart) to set up your workspace.

---

## üìÇ Where are the examples and templates?

You can find:

- [Example use cases](https://github.com/orgs/askui/repositories?q=askui-example-*)
- [Templates for testing and automation](https://github.com/askui/askui-agent-templates)
- [Customer stories](https://www.askui.com/customer-stories)