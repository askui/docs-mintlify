---
title: "WIP: Best Practices for Reliable Automation"
description: "Provide guidelines on designing robust automation scripts, including error handling, retries, and validation steps"
---

### 1. Misspellings of Words

Problem: The OCR model sometimes misreads characters, especially in certain fonts or noisy images. This can result in words being misclassified or misspelled, which then causes the automation to fail when it searches for exact matches.

Example:

<Columns cols={2}>
  <Card>
    <div style={{ fontWeight: 'bold', borderBottom: '2px solid #ccc', display: 'inline-block', paddingBottom: '2px', marginBottom: '12px' }}>
      Expected (Truth)
    </div>

    <div>
      <code>Hallo</code>
    </div>
  </Card>

  <Card>
    <div style={{ fontWeight: 'bold', borderBottom: '2px solid #ccc', display: 'inline-block', paddingBottom: '2px', marginBottom: '12px' }}>
      OCR Output (Prediction)
    </div>

    <div>
      <code>HaII0</code>
    </div>
  </Card>
</Columns>

### Solutions:

### Re-Teach the OCR Model Using AskUIâ€™s OCR Re-Teaching App

You can directly correct OCR predictions and improve model accuracy by training your workspace-specific model.

### Steps:

1. Start the AskUI shell:

   ```bash
   bash
   
   askui-shell
   ```
2. Launch the OCR Teaching App:

   ```bash
   bash
   
   AskUI-StartOCRTeaching
   ```
3. Upload a screenshot containing the misclassified word (e.g., â€œHalloâ€).
4. Switch to **Character-Level Mode** for precise corrections.
5. Select the wrongly detected word (`HaII0`) and replace it with the correct label: `Hallo`.
6. Click **"Copy Model"** to copy the newly trained model ID.
7. In your automation code (e.g., `askui-helper.ts`), update the `exec()` call to use the new model:

```
ts
CopyEdit
await aui.click().text("Hallo").exec([{
    "task": "e2e_ocr",
    "architecture": "easy_ocr",
    "version": "1",
    "interface": "online_learning",
    "useCase": "<your-workspace-id>",
    "tags": ["char_level"]
}])
```

## 2. Text Detection Issues

### Icon Text Merging\*\*

**Problem:** Sometimes, Text Detector/annotation tool, **merges an icon and texts into one**, even though they look merged on screen.

**Example:** Say you want to click **just the name** â€œAlice Johnsonâ€ field or **just the position** field in a interface - but OCR detects them as one long string:

<Columns cols={2}>
  <Card title="âœ… Expected Behavior">
    ğŸ–¼ï¸ *Icon and Text are detected separately:*
    Â 
    ![image.png](/IconTextMergingExpectedBehaviour1.png)
    Â 
    ğŸ§‘ âœ… Name âœ…â€ƒâ€ƒğŸ¤– âœ… Role âœ…
    Â 
    ğŸ‘ Works with `click().text("Name")` or `click().text("Name")`
  </Card>

  <Card title="âŒ Actual Issue">
    ğŸ–¼ï¸ *Icon and text are detected together:*
    Â 
    ![Icon Text Merging Expected Behaviour2.png](/images/IconTextMergingExpectedBehaviour2.png)
    Â 
    `ğŸ§‘ Name` âŒâ€ƒâ€ƒğŸ¤– âœ… Role âœ…
    Â 
    ğŸ‘ Can't find `click().text("Name")`.
  </Card>
</Columns>

**Solutions:**

### Option 1: Re-Teach the OCR Model to ignore the icon.

1. Start Re-Teachting App
2. Teach the Text Recognition to ignore the icon
3. Use the Custom Model.

```yaml
await aui.click().text("Alice Johnson").exec([{
        "task": "e2e_ocr",
        "architecture": "easy_ocr",
        "version": "1",
        "interface": "online_learning",
        "useCase": "<your-workspace-id>",
        "tags": ["word_level"]
    }])
```

### Option 2: Use Default Word-Level Detection (Best Practice)

```tsx
await aui.click().text("Alice Johnson").exec([{
        "task": "e2e_ocr",
        "architecture": "easy_ocr",
        "version": "1",
        "interface": "online_learning",
        "useCase": "00000000_0000_0000_0000_000000000000",
        "tags": ["word_level"]
    }])
```

> Breaks up merged strings into individual words.

### Option 3: Use Custom Model Word-Level Detection

```tsx
await aui.click().text("Alice Johnson").exec([{
        "task": "e2e_ocr",
        "architecture": "easy_ocr",
        "version": "1",
        "interface": "online_learning",
        "useCase": "<your-workspace-id>",
        "tags": ["word_level"]
    }])
```

> Breaks up merged strings into individual words.y.

### Merged Texts

**Problem:** Sometimes, Text Detector/ annotation tool, **merges two separate texts into one**, even though they look clearly split on screen.

**Example:** Say you want to click **just the name** â€œAlice Johnsonâ€ field or **just the position** field in a interface - but OCR detects them as one long string:

**âœ… Expected Behavior**

ğŸ–¼ï¸ _Text fields detected separately:_
![image.png](/MergedTextExpectedBehaviour.png)
`Alice Johnson` âœ…â€ƒâ€ƒSoftware Engineer âœ…
ğŸ‘ Works with `text("Alice Johnson")` or `text("Software Engineer")`
**âŒ Actual Issue**
ğŸ–¼ï¸ _Texts merged into one block:_
![image.png](/MergedTextActualIssue.png)
`Alice Johnson Software Engineer`âŒ
ğŸ‘ Can't find either one on its own.

<Columns cols={2}>
<Card title="âœ… Expected Behavior">
ğŸ–¼ï¸ _Text fields detected separately:_
&nbsp;
![image.png](/MergedTextExpectedBehaviour.png)
&nbsp;
`Alice Johnson` âœ…â€ƒâ€ƒSoftware Engineer âœ…
&nbsp;
ğŸ‘ Works with `text("Alice Johnson")` or `text("Software Engineer")`
</Card>
  
<Card title="âŒ Actual Issue">
ğŸ–¼ï¸ _Texts merged into one block:_
&nbsp;
![image.png](/MergedTextActualIssue.png)
&nbsp;
`Alice Johnson Software Engineer`âŒ
&nbsp;
ğŸ‘ Can't find either one on its own.
</Card>

</Columns>



**Solutions:**

### Option 1: Use Default Word-Level Detection (Best Practice)

```tsx
await aui.click().text("Alice Johnson").exec([{
        "task": "e2e_ocr",
        "architecture": "easy_ocr",
        "version": "1",
        "interface": "online_learning",
        "useCase": "00000000_0000_0000_0000_000000000000",
        "tags": ["word_level"]
    }])
```

> Breaks up merged strings into individual words.

### Option 2: Use Custom Model Word-Level Detection

```tsx
await aui.click().text("Alice Johnson").exec([{
        "task": "e2e_ocr",
        "architecture": "easy_ocr",
        "version": "1",
        "interface": "online_learning",
        "useCase": "<your-workspace-id>",
        "tags": ["word_level"]
    }])
```

> Breaks up merged strings into individual words.

### Option 3: Use Relative Positioning (Fallback)

```tsx

await aui.moveMouseRelativeTo(0, left).containsText("Name").exec()
```

> Useful when text detection still merges blocks. Navigates close enough to act anyway.

### **Text Seperation**

**Problem:** Sometimes, Text Detector/ annotation tool, septerates a text into **two texts**, even though they look clearly merged on screen.

**Example:** Say you want to click **just the name** â€œAlice Johnsonâ€ field or **just the position** field in a interface - but OCR detects them as two words:

**âœ… Expected Behavior**

ğŸ–¼ï¸ Words _are detected as one sentence:_

![image.png](attachment:263d543a-fa41-42ee-8c33-73db69d84525:image.png)

`Alice Johnson` âœ…â€ƒ

ğŸ‘ Works with `text("Alice Johnson")`

**âŒ Actual Issue**

ğŸ–¼ï¸ Words _are detected as seperated texts:_

![image.png](attachment:1e50bb77-6b65-4f95-a16f-22baf51cb0ec:image.png)

`Alice`âŒ `Johnson`âŒ

ğŸ‘ Can't find either `text("Alice Johnson")` on its own.

**Solutions:**

### Option 1: Use Default Word-Level Detection (Best Practice)

```tsx
await aui.click().text("Alice Johnson").exec([{
        "task": "e2e_ocr",
        "architecture": "easy_ocr",
        "version": "1",
        "interface": "online_learning",
        "useCase": "00000000_0000_0000_0000_000000000000",
        "tags": ["word_level"]
    }])
```

> Breaks up merged strings into individual words.

### Option 2: Use Custom Model Word-Level Detection

```tsx
await aui.click().text("Alice Johnson").exec([{
        "task": "e2e_ocr",
        "architecture": "easy_ocr",
        "version": "1",
        "interface": "online_learning",
        "useCase": "<your-workspace-id>",
        "tags": ["word_level"]
    }])
```

> Breaks up merged strings into individual words.

### **Vertical Text Merging**

**Problem:** Sometimes, Text Detector/ annotation tool, merges two lines to one text, even though they look clearly as two lines on screen.

**Example:** Say you want to click **just the name** â€œAlice Johnsonâ€ field or **just the position** field in a interface - but OCR detects them as one:

**âœ… Expected Behavior**

ğŸ–¼ï¸ Texts _are detected as two lines:_

![image.png](attachment:43f0d240-8244-46db-a197-14970dae1a42:image.png)

`Alice Johnson` âœ…â€ƒ

ğŸ‘ Works with `text("Alice Johnson")`

**âŒ Actual Issue**

ğŸ–¼ï¸ Texts _are detected as one text:_

![image.png](attachment:9df90008-3f78-40cb-b9fa-ecb1288e5c93:image.png)

`<no words recognized>`âŒ

ğŸ‘ Can't find either `text("Alice Johnson")` on its own.

**Solutions:**

### Option 1: Use Default Word-Level Detection (Best Practice)

```tsx
await aui.click().text("Alice Johnson").exec([{
        "task": "e2e_ocr",
        "architecture": "easy_ocr",
        "version": "1",
        "interface": "online_learning",
        "useCase": "00000000_0000_0000_0000_000000000000",
        "tags": ["word_level"]
    }])
```

> Breaks up merged strings into individual words.

### Option 2: Use Custom Model Word-Level Detection

```tsx
await aui.click().text("Alice Johnson").exec([{
        "task": "e2e_ocr",
        "architecture": "easy_ocr",
        "version": "1",
        "interface": "online_learning",
        "useCase": "<your-workspace-id>",
        "tags": ["word_level"]
    }])
```

> Breaks up merged strings into individual words.

### **Single Character not Detected**

**Problem:** Sometimes, Text Detector/ annotation tool, does not detect single charactors, even though they look clearly on screen.

**Example:** Say you want to click **just the char** â€œ3â€ - but OCR does not detects them:

**âœ… Expected Behavior**

ğŸ–¼ï¸ Single chars are detected\*:\*

![image.png](attachment:0507ec4b-e8d0-4fe9-923f-d21a273aa760:image.png)

`1` âœ… `2` âœ… `3` âœ…â€ƒ

ğŸ‘ Works with `text("2")`

**âŒ Actual Issue**

ğŸ–¼ï¸ Char 2 is not detected\*:\*

![image.png](attachment:9fc279f2-2a9b-4d9f-a17e-7ce7161572e1:image.png)

`1` âœ… `2` âŒ `3` âœ…â€ƒ

ğŸ‘ Can't find either `text("2")` on its own.

**Solutions:**

### Option 1: AI Element

1. Follow tutorial

### **Text not Detected**

**Problem:** Sometimes, for no apparent reason, Text Detector/ annotation tool does not detect a text, even though they see it clearly on screen.

**Example:** Say you want to click **just the name** â€œAlice Johnsonâ€ field - but OCR does not detects the text at all:

| Alice Johnson |
| ------------- |

**âœ… Expected Behavior**

ğŸ–¼ï¸ _Text was detected:_

![image.png](attachment:263d543a-fa41-42ee-8c33-73db69d84525:image.png)

`Alice Johnson` âœ…â€ƒ

ğŸ‘ Works with `text("Alice Johnson")`

**âŒ Actual Issue**

ğŸ–¼ï¸ _Text wasnâ€™t detected_

![image.png](attachment:63074214-cbcc-4b61-b746-ac9a50121f02:image.png)

`Alice Johnson`âŒ

ğŸ‘ Can't find either `text("Alice Johnson")` on its own.

**Solutions:**

### Option 1: AI Element

1. Select the Text as AI Element